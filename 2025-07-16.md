## ELK + Filebeat로 Spring Boot 로그 수집하기 (2025-07-16)

###  Spring Boot 로그를 Filebeat → Logstash → Elasticsearch → Kibana로 연동해 수집하고 시각화하는 과정

### ✅ 목표
Spring Boot 로그를 ELK Stack으로 중앙 수집

Filebeat로 로그 파일 수집

Logstash로 파싱 및 Elasticsearch 저장

Kibana에서 실시간 시각화

### 🔧 1. 로그 포맷 구성
/app/logs/app.log 위치에 JSON 포맷으로 로그를 저장함 (예: Logback 사용 시 JSON encoder 설정 필요)

### 🐳 2. Docker Network 구성
bash
```
docker network create logging-net
```
모든 컨테이너가 logging-net이라는 외부 브리지 네트워크를 공유하게 설정

📦 3. docker-compose.yml - ELK 구성
yaml
```
version: '3.8'

services:
elasticsearch:
image: docker.elastic.co/elasticsearch/elasticsearch:8.13.0
environment:
- discovery.type=single-node
- xpack.security.enabled=false
- TZ=Asia/Seoul
- ES_JAVA_OPTS=-Xms1g -Xmx1g
ports:
- "9200:9200"
volumes:
- esdata:/usr/share/elasticsearch/data
networks:
- logging-net

kibana:
image: docker.elastic.co/kibana/kibana:8.13.0
environment:
- ELASTICSEARCH_HOSTS=http://elkserver-elasticsearch-1:9200
- TZ=Asia/Seoul
ports:
- "5601:5601"
depends_on:
- elasticsearch
networks:
- logging-net

logstash:
image: docker.elastic.co/logstash/logstash:8.13.0
volumes:
- ./logstash/pipeline:/usr/share/logstash/pipeline
ports:
- "5044:5044"
- "9600:9600"
depends_on:
- elasticsearch
networks:
- logging-net

volumes:
esdata:

networks:
logging-net:
external: true

```
### 주의 : logging-net은 external: true 설정 필요. 없을 경우 compose가 network label 충돌로 실행 안 됨.

#### ⚙️ 4. Logstash 설정 (logstash.conf)
conf
```
input {
beats {
port => 5044
}
}

filter {
json {
source => "message"
}
date {
match => ["@timestamp", "ISO8601"]
}
mutate {
remove_field => ["host", "agent", "input", "ecs", "log", "tags"]
}
}

output {
elasticsearch {
hosts => ["http://elasticsearch:9200"]
index => "springboot-logs-%{+YYYY.MM.dd}"
}
stdout { codec => rubydebug }
}
```
#### 📦 5. Filebeat 설정 (filebeat.yml)
yaml
```
filebeat.inputs:
- type: log
  enabled: true
  paths:
    - /app/logs/*.log
      json.keys_under_root: true
      json.add_error_key: true
      json.message_key: message

output.logstash:
hosts: ["logstash:5044"]

setup.kibana:
host: "http://kibana:5601"

logging.level: info
logging.to_files: true
logging.files:
path: /usr/share/filebeat/logs
name: filebeat.log
keepfiles: 7
permissions: 0644

```
#### 🚫-> Filebeat도 동일한 logging-net 네트워크에 연결되어야 함 

### 🔍 6. 상태 확인 및 문제 해결
✅ 정상 로그 수집 시
Kibana에서 .ds-filebeat-8.13.0-* 인덱스를 통해 로그 확인 가능

json
```
{
"@timestamp": "2025-07-16T08:28:48.274Z",
"log.file.path": "/app/logs/app.log",
"message": "Resolving eureka endpoints via configuration"
}
```

## ❌ 오류 예시 및 해결
Elasticsearch Unreachable: Filebeat/Logstash가 Elasticsearch에 연결 실패 → DNS 이름 확인 (elkserver-elasticsearch-1)

docker-compose에서 external network 오류 → external: true로 명시 필요

Filebeat 로그가 JSON 파싱 안 될 시 → json.message_key, json.keys_under_root 확인 

**<< Json형태로 받는 message와 다른 형태로 들어와 인식할 수 없었음 >>**

# 📌 느낀 점
Docker 네트워크 이름 충돌과 컨테이너 내 서비스 DNS 이름 주의!

ELK 구성 자체는 어렵지 않지만 각 요소 간 연결을 꼼꼼히 확인해야 함

Logstash 필터 설정은 Kibana 필드 클린업에 매우 중요